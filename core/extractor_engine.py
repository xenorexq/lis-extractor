"""
æ•°æ®æŠ½å–å¼•æ“
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæ‰§è¡Œå®Œæ•´çš„ ETL æµç¨‹
"""
import os
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd
import yaml
from datetime import datetime
from PyQt6.QtCore import QObject, pyqtSignal, QThread

from .data_loader import DataLoader
from .column_mapper import ColumnMapper
from .test_mapper import TestMapper
from .value_parser import ValueParser
from .qc_reporter import QCReporter
from .utils import parse_datetime, generate_run_id


class ExtractorEngine(QObject):
    """
    æ•°æ®æŠ½å–å¼•æ“ï¼ˆæ”¯æŒå¤šçº¿ç¨‹ï¼‰
    """
    progress = pyqtSignal(int, str)  # (percentage, message)
    log = pyqtSignal(str)  # log message
    finished = pyqtSignal(dict)  # result dict
    error = pyqtSignal(str)
    
    def __init__(self, profile_path: str):
        super().__init__()
        self.profile_path = profile_path
        self.profile = None
        self.run_id = generate_run_id()
        self._is_cancelled = False
    
    def load_profile(self) -> bool:
        """åŠ è½½ profile é…ç½®"""
        try:
            with open(self.profile_path, 'r', encoding='utf-8') as f:
                self.profile = yaml.safe_load(f)
            self.log.emit(f"âœ“ åŠ è½½é…ç½®æ–‡ä»¶: {self.profile['id']}")
            return True
        except Exception as e:
            self.error.emit(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def cancel(self):
        """å–æ¶ˆè¿è¡Œ"""
        self._is_cancelled = True
        self.log.emit("âš ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    
    def run(self, file_or_folder: str, output_dir: str):
        """
        æ‰§è¡Œå®Œæ•´çš„æŠ½å–æµç¨‹
        
        Args:
            file_or_folder: è¾“å…¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        try:
            if not self.load_profile():
                return
            
            self.progress.emit(0, "å¼€å§‹å¤„ç†...")
            
            # 1. æŸ¥æ‰¾æ‰€æœ‰ Excel æ–‡ä»¶
            self.log.emit("ğŸ“ æ‰«ææ–‡ä»¶...")
            loader = DataLoader()
            excel_files = loader.find_excel_files(file_or_folder)
            self.log.emit(f"âœ“ æ‰¾åˆ° {len(excel_files)} ä¸ª Excel æ–‡ä»¶")
            
            if not excel_files:
                self.error.emit("æœªæ‰¾åˆ°ä»»ä½• Excel æ–‡ä»¶")
                return
            
            self.progress.emit(10, f"æ‰¾åˆ° {len(excel_files)} ä¸ªæ–‡ä»¶")
            
            # 2. åŠ è½½æ‰€æœ‰æ–‡ä»¶
            self.log.emit("ğŸ“– è¯»å–æ–‡ä»¶...")
            skip_rows = self.profile.get('signature', {}).get('skip_top_rows', 0)
            
            all_data = []
            for idx, file_path in enumerate(excel_files):
                if self._is_cancelled:
                    return
                
                try:
                    progress_pct = 10 + int((idx / len(excel_files)) * 30)
                    self.progress.emit(progress_pct, f"è¯»å– {idx+1}/{len(excel_files)}")
                    
                    df = loader.load_full_file(file_path, skip_rows)
                    all_data.append((file_path, df))
                    self.log.emit(f"âœ“ {os.path.basename(file_path)}: {len(df)} è¡Œ")
                except Exception as e:
                    self.log.emit(f"âœ— è·³è¿‡ {os.path.basename(file_path)}: {str(e)}")
            
            if not all_data:
                self.error.emit("æ‰€æœ‰æ–‡ä»¶è¯»å–å¤±è´¥")
                return
            
            # 3. åˆå¹¶æ•°æ®
            self.progress.emit(40, "å‡†å¤‡åˆå¹¶æ•°æ®...")
            self.log.emit("ğŸ”— åˆå¹¶æ‰€æœ‰æ•°æ®...")

            # åˆ†æ‰¹åˆå¹¶ä»¥æä¾›è¿›åº¦åé¦ˆ
            if len(all_data) > 1:
                total_files = len(all_data)
                dfs_to_concat = []

                # æ”¶é›†é˜¶æ®µ (40-42%)
                for idx, (_, df) in enumerate(all_data):
                    dfs_to_concat.append(df)
                    if (idx + 1) % max(1, total_files // 3) == 0:
                        pct = 40 + int((idx / total_files) * 2)
                        self.progress.emit(pct, f"æ”¶é›†æ•°æ® {idx+1}/{total_files}...")

                # å®é™…åˆå¹¶é˜¶æ®µ (42-45%) - è¿™æ˜¯è€—æ—¶æ“ä½œ
                self.progress.emit(42, "æ‰§è¡Œåˆå¹¶æ“ä½œ...")
                df_combined = pd.concat(dfs_to_concat, ignore_index=True)
                self.progress.emit(45, f"åˆå¹¶å®Œæˆ: {len(df_combined):,} è¡Œ")
            else:
                df_combined = all_data[0][1].copy() if all_data else pd.DataFrame()
                self.progress.emit(45, f"æ•°æ®å‡†å¤‡å®Œæˆ: {len(df_combined):,} è¡Œ")

            self.log.emit(f"âœ“ åˆå¹¶åæ€»è¡Œæ•°: {len(df_combined)}")
            
            # 4. åº”ç”¨åˆ—æ˜ å°„
            self.progress.emit(46, "åº”ç”¨å­—æ®µæ˜ å°„...")
            self.log.emit("ğŸ”„ åº”ç”¨å­—æ®µæ˜ å°„...")
            column_mapping = self.profile.get('column_mapping', {})
            mapper = ColumnMapper(column_mapping)

            self.progress.emit(48, f"æ˜ å°„ {len(column_mapping)} ä¸ªå­—æ®µ...")
            df_mapped = mapper.apply(df_combined)

            self.progress.emit(50, "å­—æ®µæ˜ å°„å®Œæˆ")
            self.log.emit(f"âœ“ æ˜ å°„å­—æ®µ: {list(column_mapping.keys())}")
            
            # 5. åº”ç”¨æ£€éªŒé¡¹ç›®æ˜ å°„
            self.progress.emit(60, "æ ‡å‡†åŒ–æ£€éªŒé¡¹ç›®...")
            self.log.emit("ğŸ”¬ æ ‡å‡†åŒ–æ£€éªŒé¡¹ç›®...")
            test_mapping = self.profile.get('test_mapping', {})
            test_mapper = TestMapper(test_mapping)

            # åœ¨æ˜ å°„å‰ï¼Œæ£€æµ‹å®Œæ•´æ•°æ®ä¸­çš„æ‰€æœ‰é¡¹ç›®
            if 'test_name' in df_mapped.columns:
                all_tests_in_data = set(df_mapped['test_name'].dropna().unique())
                selected_tests = set(test_mapping.keys())

                # æ£€æµ‹æ˜¯å¦æœ‰æœªåœ¨profileä¸­é€‰æ‹©çš„æ–°é¡¹ç›®
                new_tests = all_tests_in_data - selected_tests
                if new_tests:
                    self.log.emit(f"âš ï¸ è­¦å‘Š: å‘ç° {len(new_tests)} ä¸ªé¢„è§ˆæ—¶æœªå‡ºç°çš„æ£€éªŒé¡¹ç›®:")
                    # æ˜¾ç¤ºå‰10ä¸ªæ–°é¡¹ç›®
                    for test in list(new_tests)[:10]:
                        self.log.emit(f"   - {test}")
                    if len(new_tests) > 10:
                        self.log.emit(f"   ... è¿˜æœ‰ {len(new_tests)-10} ä¸ª")
                    self.log.emit(f"   è¿™äº›é¡¹ç›®å°†è¢«è¿‡æ»¤æ‰ï¼ˆå› ä¸ºdrop_unknown_tests=Trueï¼‰")
                    self.log.emit(f"   å¦‚éœ€åŒ…å«ï¼Œè¯·é‡æ–°è¿è¡Œå‘å¯¼å¹¶é€‰æ‹©æ›´å¤§çš„é¢„è§ˆè¡Œæ•°")

            df_mapped = test_mapper.apply(df_mapped)

            # è¿‡æ»¤é€‰ä¸­çš„é¡¹ç›®
            selected_tests = set(test_mapping.keys())
            df_filtered = test_mapper.filter_selected_tests(df_mapped, selected_tests)
            self.log.emit(f"âœ“ ä¿ç•™ {len(selected_tests)} ä¸ªé¡¹ç›®ï¼Œ{len(df_filtered)} è¡Œ")
            
            # 6. è§£ææ•°å€¼
            self.progress.emit(65, "è§£ææ£€éªŒç»“æœ...")
            self.log.emit("ğŸ”¢ è§£ææ£€éªŒç»“æœ...")
            value_parsing = self.profile.get('value_parsing', {})
            value_parser = ValueParser(value_parsing)

            self.progress.emit(68, f"è§£æ {len(df_filtered)} è¡Œæ•°å€¼...")
            df_parsed = value_parser.apply(df_filtered)
            self.progress.emit(72, "æ•°å€¼è§£æå®Œæˆ")
            
            # 7. å¤„ç†æ—¥æœŸæ—¶é—´
            self.progress.emit(74, "å¤„ç†æ—¥æœŸæ—¶é—´...")
            self.log.emit("ğŸ“… å¤„ç†æ—¥æœŸæ—¶é—´...")
            if 'sample_datetime' in df_parsed.columns:
                # å…ˆç»Ÿè®¡åŸå§‹éç©ºå€¼æ•°é‡ï¼ˆä¸å¤åˆ¶æ•´åˆ—ï¼Œåªè®¡æ•°ï¼‰
                original_non_null = df_parsed['sample_datetime'].notna().sum()
                self.log.emit(f"   åŸå§‹æ•°æ®ä¸­æœ‰ {original_non_null} è¡ŒåŒ…å«æ—¥æœŸ")

                # å¦‚æœæœ‰å¤§é‡æ—¥æœŸéœ€è¦è¯Šæ–­å¤±è´¥æƒ…å†µï¼Œæ‰ä¿å­˜æ ·æœ¬
                if original_non_null > 0:
                    # åªä¿å­˜å‰10ä¸ªåŸå§‹å€¼æ ·æœ¬ç”¨äºè¯Šæ–­ï¼ˆè€Œéæ•´åˆ—å¤åˆ¶ï¼‰
                    original_samples = df_parsed['sample_datetime'].dropna().head(10).tolist()

                # ä½¿ç”¨ pandas çš„å‘é‡åŒ–æ—¥æœŸè§£æï¼ˆæ¯” apply å¿«å¾—å¤šï¼‰
                df_parsed['sample_datetime'] = pd.to_datetime(
                    df_parsed['sample_datetime'],
                    errors='coerce',  # æ— æ³•è§£æçš„è®¾ä¸º NaT
                    infer_datetime_format=True,  # è‡ªåŠ¨æ¨æ–­æ ¼å¼ï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
                )

                # æ£€æŸ¥è§£æåæœ‰å¤šå°‘æˆåŠŸ
                parsed_non_null = df_parsed['sample_datetime'].notna().sum()
                self.log.emit(f"   æˆåŠŸè§£æ {parsed_non_null} ä¸ªæ—¥æœŸ")

                # è¯¦ç»†è¯Šæ–­å¤±è´¥çš„æƒ…å†µ
                if parsed_non_null < original_non_null:
                    failed_count = original_non_null - parsed_non_null
                    self.log.emit(f"   âš ï¸ è­¦å‘Šï¼š{failed_count} ä¸ªæ—¥æœŸè§£æå¤±è´¥")

                    # æ˜¾ç¤ºåŸå§‹æ ·æœ¬ï¼ˆç”¨äºè°ƒè¯•æ ¼å¼é—®é¢˜ï¼‰
                    if original_samples:
                        self.log.emit(f"   åŸå§‹æ•°æ®æ ·æœ¬: {original_samples[:5]}")

                if parsed_non_null == 0 and original_non_null > 0:
                    self.log.emit("   âŒ é”™è¯¯ï¼šæ‰€æœ‰æ—¥æœŸè§£æå¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥æœŸæ ¼å¼")
                elif parsed_non_null < original_non_null * 0.5 and original_non_null > 10:
                    # å¦‚æœå¤±è´¥ç‡è¶…è¿‡50%ä¸”æœ‰è¶³å¤Ÿæ ·æœ¬ï¼Œå‘å‡ºè­¦å‘Š
                    failure_rate = (original_non_null - parsed_non_null) / original_non_null * 100
                    self.log.emit(f"   âš ï¸ è­¦å‘Šï¼šæ—¥æœŸè§£æå¤±è´¥ç‡è¾ƒé«˜ ({failure_rate:.1f}%)ï¼Œå»ºè®®æ£€æŸ¥æ—¥æœŸæ ¼å¼")
            else:
                self.log.emit("   âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° sample_datetime åˆ—")
            
            # 8. ç”Ÿæˆ labs_long
            self.progress.emit(80, "ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡º...")
            self.log.emit("ğŸ“‹ ç”Ÿæˆæ ‡å‡†åŒ–é•¿è¡¨...")
            
            # é€‰æ‹©è¾“å‡ºåˆ—
            output_columns = [
                'patient_id', 'visit_id', 'sample_datetime',
                'test_name', 'test_code', 'test_value', 'value_numeric', 'value_flag',
                'unit', 'unit_std', 'ref_range', 'result_flag', 'specimen_type'
            ]
            
            # åŠ¨æ€æ·»åŠ  I just want it åˆ—
            ijwi_cols = [col for col in df_parsed.columns if col.startswith('ijwi_')]
            output_columns.extend(sorted(ijwi_cols))
            
            available_columns = [col for col in output_columns if col in df_parsed.columns]
            labs_long = df_parsed[available_columns].copy()
            
            # æ·»åŠ å…ƒæ•°æ®
            labs_long['profile_id'] = self.profile['id']
            labs_long['run_id'] = self.run_id
            
            self.log.emit(f"âœ“ ç”Ÿæˆ labs_long: {len(labs_long)} è¡Œ")
            
            # 9. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
            self.progress.emit(85, "ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
            self.log.emit("ğŸ“Š ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
            qc = QCReporter()
            report = qc.analyze(df_combined, labs_long, self.profile['id'])
            self.log.emit("âœ“ è´¨é‡åˆ†æå®Œæˆ")

            # 10. å¯¼å‡ºæ–‡ä»¶
            self.progress.emit(90, "å¯¼å‡ºæ–‡ä»¶...")
            self.log.emit("ğŸ’¾ å¯¼å‡ºæ–‡ä»¶...")

            try:
                os.makedirs(output_dir, exist_ok=True)
            except PermissionError as e:
                self.error.emit(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• (æƒé™ä¸è¶³): {output_dir}")
                return
            except OSError as e:
                self.error.emit(f"åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {str(e)}")
                return

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            # å¯¼å‡º labs_long
            self.progress.emit(92, f"å¯¼å‡ºæ•°æ® ({len(labs_long)} è¡Œ)...")
            output_file = os.path.join(output_dir, f'labs_long_{timestamp}.xlsx')

            try:
                labs_long.to_excel(output_file, index=False, engine='openpyxl')
                self.log.emit(f"âœ“ å¯¼å‡º: {os.path.basename(output_file)}")
            except PermissionError:
                self.error.emit(f"æ— æ³•å†™å…¥æ–‡ä»¶ (æƒé™ä¸è¶³): {output_file}")
                return
            except IOError as e:
                self.error.emit(f"å¯¼å‡ºæ•°æ®å¤±è´¥ (ç£ç›˜é”™è¯¯): {str(e)}")
                return
            except Exception as e:
                self.error.emit(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {str(e)}")
                return

            # å¯¼å‡ºè´¨é‡æŠ¥å‘Š
            self.progress.emit(97, "å¯¼å‡ºè´¨é‡æŠ¥å‘Š...")
            qc_file = os.path.join(output_dir, f'qc_report_{timestamp}.xlsx')

            try:
                qc.export_to_excel(qc_file)
                self.log.emit(f"âœ“ å¯¼å‡º: {os.path.basename(qc_file)}")
            except PermissionError:
                self.log.emit(f"âš ï¸ è´¨é‡æŠ¥å‘Šå¯¼å‡ºå¤±è´¥ (æƒé™ä¸è¶³): {qc_file}")
                # è´¨é‡æŠ¥å‘Šå¤±è´¥ä¸åº”é˜»æ­¢ä¸»æµç¨‹
            except Exception as e:
                self.log.emit(f"âš ï¸ è´¨é‡æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {str(e)}")
            
            # 11. å®Œæˆ
            self.progress.emit(100, "å®Œæˆ!")
            self.log.emit("=" * 50)
            self.log.emit("âœ… æŠ½å–å®Œæˆ!")
            self.log.emit(f"   è¾“å‡ºç›®å½•: {output_dir}")
            self.log.emit(f"   æ•°æ®è¡Œæ•°: {len(labs_long)}")
            self.log.emit(f"   æ£€éªŒé¡¹ç›®: {len(selected_tests)}")
            self.log.emit("=" * 50)
            
            result = {
                'success': True,
                'output_dir': output_dir,
                'labs_long_file': output_file,
                'qc_report_file': qc_file,
                'total_rows': len(labs_long),
                'total_tests': len(selected_tests),
                'report': report
            }
            
            self.finished.emit(result)
            
        except Exception as e:
            self.error.emit(f"å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            self.log.emit(traceback.format_exc())


class ExtractorThread(QThread):
    """
    æŠ½å–å¼•æ“çº¿ç¨‹åŒ…è£…å™¨
    """
    def __init__(self, engine: ExtractorEngine, file_or_folder: str, output_dir: str):
        super().__init__()
        self.engine = engine
        self.file_or_folder = file_or_folder
        self.output_dir = output_dir
    
    def run(self):
        """æ‰§è¡Œçº¿ç¨‹"""
        self.engine.run(self.file_or_folder, self.output_dir)

