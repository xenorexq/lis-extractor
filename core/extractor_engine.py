"""
æ•°æ®æŠ½å–å¼•æ“
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæ‰§è¡Œå®Œæ•´çš„ ETL æµç¨‹
"""
import os
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd
import yaml
from datetime import datetime
from PyQt6.QtCore import QObject, pyqtSignal, QThread

from .data_loader import DataLoader
from .column_mapper import ColumnMapper
from .test_mapper import TestMapper
from .value_parser import ValueParser
from .qc_reporter import QCReporter
from .utils import parse_datetime, generate_run_id


class ExtractorEngine(QObject):
    """
    æ•°æ®æŠ½å–å¼•æ“ï¼ˆæ”¯æŒå¤šçº¿ç¨‹ï¼‰
    """
    progress = pyqtSignal(int, str)  # (percentage, message)
    log = pyqtSignal(str)  # log message
    finished = pyqtSignal(dict)  # result dict
    error = pyqtSignal(str)
    
    def __init__(self, profile_path: str):
        super().__init__()
        self.profile_path = profile_path
        self.profile = None
        self.run_id = generate_run_id()
        self._is_cancelled = False
    
    def load_profile(self) -> bool:
        """åŠ è½½ profile é…ç½®"""
        try:
            with open(self.profile_path, 'r', encoding='utf-8') as f:
                self.profile = yaml.safe_load(f)
            self.log.emit(f"âœ“ åŠ è½½é…ç½®æ–‡ä»¶: {self.profile['id']}")
            return True
        except Exception as e:
            self.error.emit(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def cancel(self):
        """å–æ¶ˆè¿è¡Œ"""
        self._is_cancelled = True
        self.log.emit("âš ï¸ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    
    def run(self, file_or_folder: str, output_dir: str):
        """
        æ‰§è¡Œå®Œæ•´çš„æŠ½å–æµç¨‹
        
        Args:
            file_or_folder: è¾“å…¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        try:
            if not self.load_profile():
                return
            
            self.progress.emit(0, "å¼€å§‹å¤„ç†...")
            
            # 1. æŸ¥æ‰¾æ‰€æœ‰ Excel æ–‡ä»¶
            self.log.emit("ğŸ“ æ‰«ææ–‡ä»¶...")
            loader = DataLoader()
            excel_files = loader.find_excel_files(file_or_folder)
            self.log.emit(f"âœ“ æ‰¾åˆ° {len(excel_files)} ä¸ª Excel æ–‡ä»¶")
            
            if not excel_files:
                self.error.emit("æœªæ‰¾åˆ°ä»»ä½• Excel æ–‡ä»¶")
                return
            
            self.progress.emit(10, f"æ‰¾åˆ° {len(excel_files)} ä¸ªæ–‡ä»¶")
            
            # 2. åŠ è½½æ‰€æœ‰æ–‡ä»¶
            self.log.emit("ğŸ“– è¯»å–æ–‡ä»¶...")
            skip_rows = self.profile.get('signature', {}).get('skip_top_rows', 0)
            
            all_data = []
            for idx, file_path in enumerate(excel_files):
                if self._is_cancelled:
                    return
                
                try:
                    progress_pct = 10 + int((idx / len(excel_files)) * 30)
                    self.progress.emit(progress_pct, f"è¯»å– {idx+1}/{len(excel_files)}")
                    
                    df = loader.load_full_file(file_path, skip_rows)
                    all_data.append((file_path, df))
                    self.log.emit(f"âœ“ {os.path.basename(file_path)}: {len(df)} è¡Œ")
                except Exception as e:
                    self.log.emit(f"âœ— è·³è¿‡ {os.path.basename(file_path)}: {str(e)}")
            
            if not all_data:
                self.error.emit("æ‰€æœ‰æ–‡ä»¶è¯»å–å¤±è´¥")
                return
            
            # 3. åˆå¹¶æ•°æ®
            self.progress.emit(40, "åˆå¹¶æ•°æ®...")
            self.log.emit("ğŸ”— åˆå¹¶æ‰€æœ‰æ•°æ®...")
            df_combined = pd.concat([df for _, df in all_data], ignore_index=True)
            self.log.emit(f"âœ“ åˆå¹¶åæ€»è¡Œæ•°: {len(df_combined)}")
            
            # 4. åº”ç”¨åˆ—æ˜ å°„
            self.progress.emit(50, "åº”ç”¨å­—æ®µæ˜ å°„...")
            self.log.emit("ğŸ”„ åº”ç”¨å­—æ®µæ˜ å°„...")
            column_mapping = self.profile.get('column_mapping', {})
            mapper = ColumnMapper(column_mapping)
            df_mapped = mapper.apply(df_combined)
            self.log.emit(f"âœ“ æ˜ å°„å­—æ®µ: {list(column_mapping.keys())}")
            
            # 5. åº”ç”¨æ£€éªŒé¡¹ç›®æ˜ å°„
            self.progress.emit(60, "æ ‡å‡†åŒ–æ£€éªŒé¡¹ç›®...")
            self.log.emit("ğŸ”¬ æ ‡å‡†åŒ–æ£€éªŒé¡¹ç›®...")
            test_mapping = self.profile.get('test_mapping', {})
            test_mapper = TestMapper(test_mapping)
            df_mapped = test_mapper.apply(df_mapped)
            
            # è¿‡æ»¤é€‰ä¸­çš„é¡¹ç›®
            selected_tests = set(test_mapping.keys())
            df_filtered = test_mapper.filter_selected_tests(df_mapped, selected_tests)
            self.log.emit(f"âœ“ ä¿ç•™ {len(selected_tests)} ä¸ªé¡¹ç›®ï¼Œ{len(df_filtered)} è¡Œ")
            
            # 6. è§£ææ•°å€¼
            self.progress.emit(70, "è§£ææ£€éªŒç»“æœ...")
            self.log.emit("ğŸ”¢ è§£ææ£€éªŒç»“æœ...")
            value_parsing = self.profile.get('value_parsing', {})
            value_parser = ValueParser(value_parsing)
            df_parsed = value_parser.apply(df_filtered)
            
            # 7. å¤„ç†æ—¥æœŸæ—¶é—´
            self.log.emit("ğŸ“… å¤„ç†æ—¥æœŸæ—¶é—´...")
            if 'sample_datetime' in df_parsed.columns:
                # ä¿å­˜åŸå§‹å€¼ç”¨äºè¯Šæ–­
                original_values = df_parsed['sample_datetime'].copy()
                
                # å…ˆæ£€æŸ¥åŸå§‹åˆ—ä¸­æœ‰å¤šå°‘éç©ºå€¼
                original_non_null = original_values.notna().sum()
                self.log.emit(f"   åŸå§‹æ•°æ®ä¸­æœ‰ {original_non_null} è¡ŒåŒ…å«æ—¥æœŸ")
                
                # ä½¿ç”¨ pandas çš„å‘é‡åŒ–æ—¥æœŸè§£æï¼ˆæ¯” apply å¿«å¾—å¤šï¼‰
                df_parsed['sample_datetime'] = pd.to_datetime(
                    df_parsed['sample_datetime'],
                    errors='coerce',  # æ— æ³•è§£æçš„è®¾ä¸º NaT
                    infer_datetime_format=True,  # è‡ªåŠ¨æ¨æ–­æ ¼å¼ï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
                )
                
                # æ£€æŸ¥è§£æåæœ‰å¤šå°‘æˆåŠŸ
                parsed_non_null = df_parsed['sample_datetime'].notna().sum()
                self.log.emit(f"   æˆåŠŸè§£æ {parsed_non_null} ä¸ªæ—¥æœŸ")
                
                # è¯¦ç»†è¯Šæ–­å¤±è´¥çš„æƒ…å†µ
                if parsed_non_null < original_non_null:
                    failed_count = original_non_null - parsed_non_null
                    self.log.emit(f"   âš ï¸ è­¦å‘Šï¼š{failed_count} ä¸ªæ—¥æœŸè§£æå¤±è´¥")
                    
                    # æ˜¾ç¤ºå¤±è´¥çš„æ ·æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    failed_mask = df_parsed['sample_datetime'].isna() & original_values.notna()
                    if failed_mask.any():
                        failed_samples = original_values.loc[failed_mask].head(5).tolist()
                        self.log.emit(f"   å¤±è´¥æ ·æœ¬: {failed_samples}")
                
                if parsed_non_null == 0 and original_non_null > 0:
                    self.log.emit("   âŒ é”™è¯¯ï¼šæ‰€æœ‰æ—¥æœŸè§£æå¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥æœŸæ ¼å¼")
            else:
                self.log.emit("   âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° sample_datetime åˆ—")
            
            # 8. ç”Ÿæˆ labs_long
            self.progress.emit(80, "ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡º...")
            self.log.emit("ğŸ“‹ ç”Ÿæˆæ ‡å‡†åŒ–é•¿è¡¨...")
            
            # é€‰æ‹©è¾“å‡ºåˆ—
            output_columns = [
                'patient_id', 'visit_id', 'sample_datetime',
                'test_name', 'test_code', 'test_value', 'value_numeric', 'value_flag',
                'unit', 'unit_std', 'ref_range', 'result_flag', 'specimen_type'
            ]
            
            available_columns = [col for col in output_columns if col in df_parsed.columns]
            labs_long = df_parsed[available_columns].copy()
            
            # æ·»åŠ å…ƒæ•°æ®
            labs_long['profile_id'] = self.profile['id']
            labs_long['run_id'] = self.run_id
            
            self.log.emit(f"âœ“ ç”Ÿæˆ labs_long: {len(labs_long)} è¡Œ")
            
            # 9. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
            self.progress.emit(90, "ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
            self.log.emit("ğŸ“Š ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
            qc = QCReporter()
            report = qc.analyze(df_combined, labs_long, self.profile['id'])
            self.log.emit("âœ“ è´¨é‡åˆ†æå®Œæˆ")
            
            # 10. å¯¼å‡ºæ–‡ä»¶
            self.progress.emit(95, "å¯¼å‡ºæ–‡ä»¶...")
            self.log.emit("ğŸ’¾ å¯¼å‡ºæ–‡ä»¶...")
            
            os.makedirs(output_dir, exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # å¯¼å‡º labs_long
            output_file = os.path.join(output_dir, f'labs_long_{timestamp}.xlsx')
            labs_long.to_excel(output_file, index=False, engine='openpyxl')
            self.log.emit(f"âœ“ å¯¼å‡º: {os.path.basename(output_file)}")
            
            # å¯¼å‡ºè´¨é‡æŠ¥å‘Š
            qc_file = os.path.join(output_dir, f'qc_report_{timestamp}.xlsx')
            qc.export_to_excel(qc_file)
            self.log.emit(f"âœ“ å¯¼å‡º: {os.path.basename(qc_file)}")
            
            # 11. å®Œæˆ
            self.progress.emit(100, "å®Œæˆ!")
            self.log.emit("=" * 50)
            self.log.emit("âœ… æŠ½å–å®Œæˆ!")
            self.log.emit(f"   è¾“å‡ºç›®å½•: {output_dir}")
            self.log.emit(f"   æ•°æ®è¡Œæ•°: {len(labs_long)}")
            self.log.emit(f"   æ£€éªŒé¡¹ç›®: {len(selected_tests)}")
            self.log.emit("=" * 50)
            
            result = {
                'success': True,
                'output_dir': output_dir,
                'labs_long_file': output_file,
                'qc_report_file': qc_file,
                'total_rows': len(labs_long),
                'total_tests': len(selected_tests),
                'report': report
            }
            
            self.finished.emit(result)
            
        except Exception as e:
            self.error.emit(f"å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            self.log.emit(traceback.format_exc())


class ExtractorThread(QThread):
    """
    æŠ½å–å¼•æ“çº¿ç¨‹åŒ…è£…å™¨
    """
    def __init__(self, engine: ExtractorEngine, file_or_folder: str, output_dir: str):
        super().__init__()
        self.engine = engine
        self.file_or_folder = file_or_folder
        self.output_dir = output_dir
    
    def run(self):
        """æ‰§è¡Œçº¿ç¨‹"""
        self.engine.run(self.file_or_folder, self.output_dir)

